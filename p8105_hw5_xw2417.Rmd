---
title: "P8105 Homework5 Solution"
author: "Xun Wang"
date: "11/07/2019"
output: github_document
---

This file is the solution to P8105 Homework 5 from Xun Wang (xw2417).

```{r setup, message=FALSE}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))

set.seed(10)
```

#### Problem 1

This problem uses the `iris` dataset. The code chunk below loads the dataset and introduces missing values in each column.

```{r iris_missing_data}
iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species)) %>% 
  janitor::clean_names()
```

The code chunk below generates a function that takes a vector as an argument; replaces missing values; and returns the resulting vector. 

```{r replace_function}
replace_missing = function(x) {
  
  if (is.numeric(x)) {
    x[is.na(x)] = mean(x, na.rm = TRUE)
  } else if (is.character(x)) {
    x[is.na(x)] = "virginica"
  } else {
    stop("Argument x should be numeric or character")
  }
  x
}
```

The code chunk below replaces missing values in the `iris_with_missing` with

* the mean of non-missing values for numeric variables
* "virginica" for character variables

and generates a `tibble` output.

```{r replace_iris_data}
iris_complete = map_df(iris_with_missing, replace_missing)

iris_complete
```

#### Problem 2

The code chunk below creates a tidy dataframe containing data from all participants, including the subject ID, arm, and observations over time.

```{r longtitudinal_study_df, message=FALSE}
file_name = list.files(path = "data")

raw_df = map(.x = file_name, ~ read_csv(str_c("data/", .x))) %>% 
  bind_rows %>%
  mutate(file_name = file_name)
  
longitudinal_study_df = 
  raw_df %>% 
  separate(file_name, c("arm", "id"), sep = "_", remove = TRUE) %>%
  mutate(id = str_replace(id, ".csv", "")) %>% 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "observation"
  ) %>%
  select(id, arm, week, observation) %>% 
  mutate(
    id = as.factor(id),
    arm = as.factor(arm),
    #week = as.factor(week)
  ) 
```

The code chunk below makes a spaghetti plot showing observations on each subject over time.

```{r longtitudinal_study_plot}
longitudinal_study_df %>%
  ggplot(aes(x = week, y = observation, color = arm)) +
  geom_path(aes(group = id)) +
  geom_point(alpha = .5) + 
  labs(
    title = "Longitudinal study plot",
    x = "Time (week)",
    y = "Observed data"
  )
```

**Comments:** In the beginning of the experiment, the longitudinal data observed both in the control group and the experimental group are quite similar, which is around 1.5. When the experiment starts and with time goes by, the longitudinal data observed in the control group still stays stable, while the data observed in the experimental group increases to around 5.0. So the experiment might have a positive effect on the longitudinal data.

#### Problem 3

In this problem, I conduct a simulation to explore power in a simple linear regression. The code chunk below generates a function to simulate data from a simple linear regression, fit the regression model, and return estimates of regression coefficients.

```{r sim_regression_function}
sim_regression = function(n = 30, beta0 = 2, beta1) {
  
  sim_data = tibble(
    x = rnorm(n, mean = 0, sd = 1),
    y = beta0 + beta1 * x + rnorm(n, 0, 50)
  )
  
  ls_fit_sum = lm(y ~ x, data = sim_data) %>% broom::tidy()
  
  tibble(
    beta1_hat = ls_fit_sum[[2, 2]],
    p_value = ls_fit_sum[[2, 5]]
  )
}
```

First, I generate 10,000 datasets with *β1* = 0 from the SLR model by the code chunk below.

```{r beta_0}
sim_results_0 = 
  rerun(10000, sim_regression(30, 2, 0)) %>% 
  bind_rows()

sim_results_0
```

Second, the code chunk below repeats the above for *β1* = 1,2,3,4,5,6, and generates a dataframe for the simulation results.

```{r beta_multi}
sim_results = 
  tibble(slope = c(0, 1, 2, 3, 4, 5, 6)) %>% 
  mutate(
    output_lists = map(.x = slope, ~rerun(10000, sim_regression(beta1 = .x))),
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs)

sim_results
```

Third, the code chunk below makes a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of β1 on the x axis. Describe the association between effect size and power.

```{r power_plot}
sim_results %>% 
  group_by(slope) %>% 
  summarize(
    power = sum(p_value <= 0.05) / n()
  ) %>% 
  mutate(
    slope = str_c("β1 = ", slope),
    slope = fct_inorder(slope)) %>% 
  ggplot(aes(x = slope, y = power, fill = slope)) + 
  geom_bar(stat = 'identity') +
  labs(
    title = "The association between effect size and power plot",
    x = "true slope",
    y = "the power of the test"
  )
```

**Comments:** From the figure above, we can see when the effect size β1 increase, the power of the test increases. So larger effect size means more power.

Last, the code chunk below makes plots showing the relationship of average estimate of β1_hat and β1.

```{r esti_true_plots}

table_1 = 
  sim_results %>% 
  group_by(slope) %>% 
  summarize(
    all_samples = mean(beta1_hat, na.rm = TRUE)
  )

table_2 = 
  sim_results %>% 
  filter(p_value <= 0.05) %>% 
  group_by(slope) %>% 
  summarize(
    null_rejected_samples = mean(beta1_hat, na.rm = TRUE)
  )

inner_join(table_1, table_2, by = "slope") %>% 
  pivot_longer(
    all_samples:null_rejected_samples,
    names_to = "sample_type",
    values_to = "β1_hat_average"
  ) %>% 
  mutate(
    slope = str_c("β1 = ", slope),
    slope = fct_inorder(slope)) %>% 
  ggplot(aes(x = slope, y = β1_hat_average, color = sample_type)) + 
  geom_point() +
  geom_line(aes(group = sample_type)) +
  labs(
    title = "The association between average estimates and true values",
    x = "true slope",
    y = "average value of β1_hat "
  )
```

**Comments:** From the figure above, we can see the average estimates of β1_hat from both all sampels and samples for which the null was rejected increase when the true slope incrases. The average estimates of β1_hat from all sampels are very close to the true slopes but the sample average of β1_hat across  tests for which the null is rejected **isn't** approximately equal to the true value of β1. This is because the samples for which the null was rejected can't persuade people statistically to accept them and they are "black sheep" in their own sample group. 